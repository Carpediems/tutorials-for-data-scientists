---
title: "1. R API Training - Feature Selection Curves [Solution]"
author: "Thodoris Petropoulos and Chester Ismay<br>Contributors: Rajiv Shah"
output: github_document
---

Hey again! This is the first in a series of exercises to complete in order to finish your `R API Training for DataRobot` course! This exercise will help you learn how to manipulate `DataRobot Models` and `Feature Lists`.

Here are the actual sections of the notebook alongside time to complete: 

1. Connect to DataRobot. [3min]<br>
2. Create a Project. [15min]<br>
3. Create Custom Feature Lists. [15min]<br>
4. Identify Specific Models. [20min]<br>
5. Retrain Models on the custom feature lists. [10min] <br>
6. Plot performance based on the different feature lists. [30min]
7. Bonus Question

Each section will have specific instructions so do not worry if things are still blurry!

As always, consult:

- [API Documentation via CRAN Vignettes](https://CRAN.R-project.org/package=datarobot)
- [Samples](https://github.com/datarobot-community/examples-for-data-scientists)
- [Tutorials](https://github.com/datarobot-community/tutorials-for-data-scientists)

The last two links should provide you with the snippets you need to complete most of these exercises.

<b>Data</b>

The dataset we will be using throughout these exercises is the well-known `readmissions` dataset. You can access it or directly download it through DataRobot's public S3 bucket [here](https://s3.amazonaws.com/datarobot_public_datasets/10k_diabetes.csv). We have defined the variable `data` which can be used directly in project creation and links to our training dataset.

```{r}
data <- "https://s3.amazonaws.com/datarobot_public_datasets/10k_diabetes.csv"
```


### 1. Connect to DataRobot [3min]

You should already know how to do that from the introductory script. If you have a Yaml file it should be very straightforward! Else, use the `endpoint` and `token` variables to define your credentials.

```{r}

```

```{r}
```

### 2. Create a Project [10min]
Create a DataRobot Project:

1. Use the `data` variable as input.
2. Set `readmitted` as the target.
3. Start the project using explicitly the `quick` autopilot in the `mode` variable.
4. Use `AUC` as the optimization metric.
5. Set `worker_count` variable to -1 using the `UpdateProject()` function.
6. Wait for Autopilot to complete. 

While waiting, go through the documentation and the different settings that exist.

**HINT**: To initiate the project with `quick` autopilot, you will have to use two different functions: the `SetupProject()` function and the `SetTarget()` function. 

```{r}
```

### 3. Create Custom Feature Lists [15min]

Instructions:

1. Retrieve Feature Impact for the most accurate model by the validation score.
2. Create 3 different Feature Lists named `top_5`, `top_10` and `top_15`. Each featurelist will have the respective top $n$ features based on Feature Impact score.

**HINT**: Search for the `CreateFeaturelist()` function. This will help you create a new featurelist.

```{r}
```

```{r}
```

### 4. Identify Specific Models [20min]

Create a list with the models that fulfill the below requirements:

1. Model's `modelType` is 'Light Gradient', 'eXtreme Gradient', or 'Elastic-Net'.
2. Model's `samplePct` equals 64% (The amount of data the model has been trained on).

**Hint**: Look into the `filter` variable of the `ListModels()` function. That should help you find the models that have been trained on 64% of the data fast.

```{r}
```

### 5. Retrain models on the custom featurelists [10 min] 

Use the list created in `step 4` to: 

1. Retrain the models with the top_5, top_10, top_15 featurelists and 64% of the data.

```{r}
```

### 6. Plot performance based on the different featurelists [15min]

Using the knowledge that you acquired from the previous questions:

1. Create a list with all of the models retrained on `top_5`, `top_10`, and `top_15` feature lists.
2. Find the average value of the cross-validation score based on AUC for the retrained models and plot that.

**Hint**: DataRobot Model objects have an element called `featurelistName` which returns the name of the featurelist used to train that model. That should help you find the models you are looking for. Note that Blender models will often return `NA` as featurelist so they are removed from the search below.

**Hint 2**: DataRobot will not calculate cross-validation scores automatically for the retrained models. What you can do is call the `CrossValidateModel()` function in order to calculate cross validation.

**Warning**: Do not forget to wait after you ask DataRobot to calculate cross validation scores!

```{r}
```

```{r}
```

```{r}
```

```{r}
```

What do you see?

### Verification

To verify that you have completed everything correctly, look at the `Light Gradient Boosting on ElasticNet Predictions` model that was trained on 64% of the data with the Informative Features featurelist. The cross-validation score for AUC should be 0.6991.

### Bonus Question

You might have noticed that the first list of models we created had 5 (might change with DR releases) models. It makes sense that since we want to run each one of these models using 3 different feature lists, we should have ended with 15 models. That is not the case as we had 12 models in the end. Can you think why that is the case?

#### Bonus Question Answer:

The 5 models we retrieved are not unique. Some of them are the same just trained on different featurelists. DataRobot identifies that we have already initiated model building with a featurelist and it will not create a duplicate model.
