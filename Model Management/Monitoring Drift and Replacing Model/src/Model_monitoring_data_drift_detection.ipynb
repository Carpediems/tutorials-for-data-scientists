{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model monitoring: data drift detection\n",
    "\n",
    "**Author:** Andrew Kruchko\n",
    "\n",
    "**Contributors:** Thodoris Petropoulos\n",
    "\n",
    "**Label:** Model Monitoring\n",
    "\n",
    "**Scope**: The scope of this notebook is to provide instructions on how to detect data drift and replace the model in the deployment.\n",
    "\n",
    "**Background**: The model performance depends on the data used for predictions. Data drift can lead to unreliable predictions which is why it should be monitored to the model replacement. \n",
    "\n",
    "**Considerations**: The endpoint \"deployments/{deployment_id}/featureDrift/\" is not yet documented publicly and is only visible in this internal build of the docs. It is subject to further possible breaking interface changes. It is labeled for release in version: v2.21\n",
    "\n",
    "**Requirements:** Python 3.7; DataRobot API version 2.20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datarobot as dr\n",
    "import yaml\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect to DataRobot and Define Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datarobot.rest.RESTClientObject at 0x1101c7490>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr.Client(config_path=\"../drconfig.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../drconfig.yaml\", 'r') as stream:\n",
    "    creds = yaml.safe_load(stream)\n",
    "token = creds['token']\n",
    "base_url = creds['base_url']\n",
    "\n",
    "project_name = '10K_Lending_Club_Loans'\n",
    "target = 'is_bad'\n",
    "metric = 'LogLoss'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. create data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dr_rest_call(url, req_func, payload=None):\n",
    "    headers = {'Authorization': f'Token {token}',\n",
    "               'Content-Type': 'application/json;charset=UTF-8'}\n",
    "    return req_func(f'{base_url}{url}', headers=headers, json=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 find Microsoft SQL Server jdbc driver among predefined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers = dr_rest_call('externalDataDrivers', requests.get)\n",
    "\n",
    "drivers = drivers.json()\n",
    "drivers_sql_serv = []\n",
    "for driver in drivers['data']:\n",
    "    if 'Microsoft SQL Server' in driver['canonicalName']:\n",
    "        drivers_sql_serv.append([driver['canonicalName'], driver['version'], driver['id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use the latest\n",
    "driver_sql_serv_id = drivers_sql_serv[-1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 create a data store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'type': 'jdbc', \n",
    "        'canonicalName': 'sql_server_lc', \n",
    "        'params': {'driverId': driver_sql_serv_id, \n",
    "                   'jdbcFields': \n",
    "                   [{'name': 'address', 'value': creds['db_address']},\n",
    "                    {'name': 'databaseName', 'value': creds['db_name']}]\n",
    "                  }}\n",
    "\n",
    "data_store_resp = dr_rest_call('externalDataStores', requests.post, payload=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data store id\n",
    "data_store = data_store_resp.json()\n",
    "data_store_id = data_store['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 create data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data source based on query \n",
    "query = \"\"\"\n",
    "select *\n",
    "from drdemodb1.cfds_demo.Credit_Analysis_Lending_Club\n",
    "where annual_inc <= 90000\n",
    "\"\"\"\n",
    "# where addr_state not in ('CA', 'FL')\n",
    "data = {'type': 'jdbc', \n",
    "        'canonicalName': 'Lending_Club_query', \n",
    "        'params': {'dataStoreId': data_store_id, \n",
    "                   'query': query}}\n",
    "\n",
    "data_src_query_resp = dr_rest_call('externalDataSources', requests.post, payload=data)\n",
    "\n",
    "data_src_query = data_src_query_resp.json()\n",
    "data_src_query_id = data_src_query['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data source based on table \n",
    "data = {'type': 'jdbc', \n",
    "        'canonicalName': 'Lending_Club_table', \n",
    "        'params': {'dataStoreId': data_store_id, \n",
    "                   'schema': 'cfds_demo',\n",
    "                   'table': 'Credit_Analysis_Lending_Club'}}\n",
    "\n",
    "data_src_table_resp = dr_rest_call('externalDataSources', requests.post, payload=data)\n",
    "\n",
    "data_src_table = data_src_table_resp.json()\n",
    "data_src_table_id = data_src_table['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_proj_id(resp):\n",
    "    \"\"\"\n",
    "    wait for the project creation\n",
    "    return the project id\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        resp_stat = requests.get(resp.headers['Location'], \n",
    "                                 headers={'Authorization': f'Token {token}', \n",
    "                                          'Content-Type': 'application/json;charset=UTF-8'})\n",
    "        resp_stat = resp_stat.json()\n",
    "\n",
    "        if resp_stat.get('id') is None:\n",
    "            time.sleep(10)\n",
    "        else:\n",
    "            proj_id = resp_stat.get('id')\n",
    "            break\n",
    "        \n",
    "    return proj_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a project based on the data source\n",
    "data = {'projectName': f'{project_name}_query',\n",
    "        'dataSourceId': data_src_query_id, \n",
    "        'user': creds['db_user'],\n",
    "        'password': creds['db_pass']}\n",
    "\n",
    "project_resp = dr_rest_call('projects', requests.post, payload=data)\n",
    "\n",
    "project_id = wait_for_proj_id(project_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the project trough python API \n",
    "projects = dr.Project.list()\n",
    "project = [pr for pr in projects if pr.id == project_id][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Project(10K_Lending_Club_Loans_query)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set target and run autopilot\n",
    "project.set_target(target=target,\n",
    "                   mode=dr.enums.AUTOPILOT_MODE.QUICK,\n",
    "                   metric=metric,\n",
    "                   worker_count=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.wait_for_autopilot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dr.ModelRecommendation.get(project.id).get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.683502\n",
      "LogLoss: 0.37276000000000004\n"
     ]
    }
   ],
   "source": [
    "# recommended model results\n",
    "print('AUC:', model.metrics['AUC']['crossValidation'])\n",
    "print('LogLoss:', model.metrics['LogLoss']['crossValidation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_deployment(data, datarobot_key, deployment_url, deployment_id):\n",
    "    # Set HTTP headers. The charset should match the contents of the file.\n",
    "    headers = {'Content-Type': 'application/json; charset=UTF-8', 'datarobot-key': datarobot_key}\n",
    "\n",
    "    url = f'{deployment_url}/predApi/v1.0/deployments/{deployment_id}/predictions'\n",
    "    \n",
    "    # Make API request for predictions\n",
    "    predictions_response = requests.post(\n",
    "        url,\n",
    "        auth=(creds['username'], creds['token']),\n",
    "        data=data,\n",
    "        headers=headers,\n",
    "    )\n",
    "\n",
    "    return predictions_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy the model\n",
    "deployment = dr.Deployment.create_from_learning_model(model_id=model.id, \n",
    "                                                      label=f'{project_name}_clf_depl',\n",
    "                                                      default_prediction_server_id=creds['pred_serv_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment.update_drift_tracking_settings(feature_drift_enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction server url, deployment id and DataRobot key\n",
    "pred_server = deployment.default_prediction_server\n",
    "\n",
    "dr_key = pred_server['datarobot-key']\n",
    "depl_url = pred_server['url']\n",
    "depl_id = deployment.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1907, 34)\n"
     ]
    }
   ],
   "source": [
    "# read and prepare a dataset to score\n",
    "df_scoring = pd.read_csv('data/10K_Lending_Club_Loans_annual_inc_above_90k.csv')\n",
    "print(df_scoring.shape)\n",
    "data_to_pred = json.dumps(df_scoring.to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-12 12:10:39.445159\n",
      "2020-05-12 12:10:44.139796\n"
     ]
    }
   ],
   "source": [
    "# get predictions\n",
    "print(str(datetime.now()))\n",
    "preds_raw = predict_deployment(data_to_pred, dr_key, depl_url, depl_id)\n",
    "print(str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning\n",
    "# The following endpoint is not yet documented publicly and is only visible in this internal build of the docs. \n",
    "# It is subject to further possible breaking interface changes. \n",
    "# It is labeled for release in version: v2.21\n",
    "\n",
    "# detect data drift\n",
    "data = {'limit': 10}\n",
    "drift_check = dr_rest_call(f'deployments/{deployment.id}/featureDrift/', requests.get, data).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_results = []\n",
    "for drift in drift_check['data']:\n",
    "    if drift['featureImpact'] > 0.5 and drift['driftScore'] > 0.5:\n",
    "        drift_results.append(drift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'featureImpact': 0.602255298259249,\n",
       "  'sampleSize': 1907,\n",
       "  'name': 'annual_inc',\n",
       "  'baselineSampleSize': 6474,\n",
       "  'driftScore': 14.165824381181023}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drift_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. model replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.6976519999999999\n",
      "LogLoss: 0.35642199999999996\n",
      "passing\n",
      "current model:  *******f6 Elastic-Net Classifier (L2 / Binomial Deviance)\n",
      "replaced model: *******70 Elastic-Net Classifier (L2 / Binomial Deviance)\n"
     ]
    }
   ],
   "source": [
    "if len(drift_results) > 0:\n",
    "    # create a project based on the data source\n",
    "    data = {'projectName': f'{project_name}_table',\n",
    "            'dataSourceId': data_src_table_id, \n",
    "            'user': creds['db_user'],\n",
    "            'password': creds['db_pass']}\n",
    "\n",
    "    project_tbl_resp = dr_rest_call('projects', requests.post, payload=data)\n",
    "\n",
    "    project_tbl_id = wait_for_proj_id(project_tbl_resp)\n",
    "    \n",
    "    # find the project trough python API \n",
    "    projects = dr.Project.list()\n",
    "    project_tbl = [pr for pr in projects if pr.id == project_tbl_id][0]\n",
    "    \n",
    "    # set target and run autopilot\n",
    "    project_tbl.set_target(target=target,\n",
    "                           mode=dr.enums.AUTOPILOT_MODE.QUICK,\n",
    "                           metric=metric,\n",
    "                           worker_count=-1)\n",
    "    \n",
    "    project_tbl.wait_for_autopilot()\n",
    "    \n",
    "    model_tbl = dr.ModelRecommendation.get(project_tbl.id).get_model()\n",
    "    \n",
    "    # recommended models results\n",
    "    print('AUC:', model_tbl.metrics['AUC']['crossValidation'])\n",
    "    print('LogLoss:', model_tbl.metrics['LogLoss']['crossValidation'])\n",
    "    \n",
    "    status, message, checks = deployment.validate_replacement_model(new_model_id=model_tbl.id)\n",
    "    print(status)\n",
    "    \n",
    "    print('current model: ', deployment.model['id'], deployment.model['type'])\n",
    "    \n",
    "    deployment.replace_model(model_tbl.id, dr.enums.MODEL_REPLACEMENT_REASON.DATA_DRIFT)\n",
    "    print('replaced model:', deployment.model['id'], deployment.model['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
